# 16x RTX 2080 GPU æœåŠ¡å™¨è®­ç»ƒæŒ‡å—

## ğŸ–¥ï¸ æœåŠ¡å™¨é…ç½®

| ç»„ä»¶ | é…ç½® |
|------|------|
| GPU | 16x NVIDIA RTX 2080 (8GB each) |
| æ€»æ˜¾å­˜ | 128 GB |
| æ¨èBatch | 256 (16 GPU Ã— 16 per GPU) |

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ä¸Šä¼ ä»£ç åˆ°æœåŠ¡å™¨

```bash
# åœ¨æœ¬åœ°æ‰§è¡Œ
rsync -avz --exclude='data/raw' --exclude='runs/' \
    /Users/macbookair/Documents/trae_projects/llm/ \
    user@gpu-server:/path/to/project/

# æˆ–ä½¿ç”¨ scp
scp -r llm/ user@gpu-server:/path/to/project/
```

### 2. æœåŠ¡å™¨ç¯å¢ƒè®¾ç½®

```bash
# SSH åˆ°æœåŠ¡å™¨
ssh user@gpu-server

# è¿›å…¥é¡¹ç›®ç›®å½•
cd /path/to/project/llm

# æ£€æŸ¥ GPU
nvidia-smi

# åˆ›å»º conda ç¯å¢ƒ
conda create -n obstacle_detection python=3.8 -y
conda activate obstacle_detection

# å®‰è£… PyTorch (CUDA 11.8)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# å®‰è£…å…¶ä»–ä¾èµ–
pip install ultralytics opencv-python-headless tensorboard

# éªŒè¯ç¯å¢ƒ
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}, GPUs: {torch.cuda.device_count()}')"
```

### 3. æ£€æŸ¥å¤šGPUç¯å¢ƒ

```bash
python src/training/train_distributed.py check
```

é¢„æœŸè¾“å‡ºï¼š
```
======================================================================
å¤šGPUè®­ç»ƒç¯å¢ƒæ£€æŸ¥ (16x RTX 2080 Server)
======================================================================
âœ“ PyTorch: 2.x.x
âœ“ CUDA: 11.8

å‘ç° 16 ä¸ª GPU:
  GPU 0: NVIDIA GeForce RTX 2080 (8.0 GB, SM 7.5)
  GPU 1: NVIDIA GeForce RTX 2080 (8.0 GB, SM 7.5)
  ...
  GPU 15: NVIDIA GeForce RTX 2080 (8.0 GB, SM 7.5)

æ€»æ˜¾å­˜: 128.0 GB
âœ“ NCCL åç«¯å¯ç”¨ (æ¨èç”¨äºå¤šGPU)
âœ“ Ultralytics: 8.x.x
======================================================================
```

### 4. ä¸Šä¼ æ•°æ®é›†

```bash
# ä¸Šä¼ æ ‡æ³¨å¥½çš„æ•°æ®é›†
rsync -avz data/yolo_dataset/ user@gpu-server:/path/to/project/llm/data/yolo_dataset/
```

### 5. å¼€å§‹è®­ç»ƒ

```bash
# ä½¿ç”¨æ‰€æœ‰16å¼ GPU
bash scripts/train_multi_gpu.sh train 100 all

# æˆ–ç›´æ¥ä½¿ç”¨ Python
python src/training/train_distributed.py ddp \
    --data configs/data.yaml \
    --model yolo11n.pt \
    --epochs 100 \
    --gpus all \
    --amp \
    --cache
```

## âš¡ è®­ç»ƒé…ç½®æ¨è

### RTX 2080 (8GB) æœ€ä¼˜é…ç½®

| å›¾åƒå¤§å° | å•å¡Batch | 16å¡æ€»Batch | æ˜¾å­˜å ç”¨ |
|----------|-----------|-------------|----------|
| 320Ã—320 | 32 | 512 | ~4GB |
| 480Ã—480 | 24 | 384 | ~5GB |
| 640Ã—640 | 16 | 256 | ~6GB |
| 800Ã—800 | 8 | 128 | ~7GB |

### å¤§Batchè®­ç»ƒæŠ€å·§

```python
# å­¦ä¹ ç‡çº¿æ€§ç¼©æ”¾
# base_lr = 0.01 (batch=64)
# å®é™… lr = base_lr * (actual_batch / 64)
lr0 = 0.01 * (256 / 64)  # = 0.04

# ä½¿ç”¨ AdamW ä¼˜åŒ–å™¨ï¼ˆå¤§batchæ›´ç¨³å®šï¼‰
optimizer = 'AdamW'

# å¢åŠ  warmup
warmup_epochs = 5

# ä½¿ç”¨æ›´å¼ºçš„æ•°æ®å¢å¼º
mixup = 0.2
mosaic = 1.0
```

## ğŸ“Š ç›‘æ§è®­ç»ƒ

### TensorBoard

```bash
# åœ¨æœåŠ¡å™¨ä¸Šå¯åŠ¨ TensorBoard
tensorboard --logdir runs/train --port 6006 --bind_all

# åœ¨æœ¬åœ°è®¾ç½® SSH éš§é“
ssh -L 6006:localhost:6006 user@gpu-server

# æœ¬åœ°æµè§ˆå™¨è®¿é—®
http://localhost:6006
```

### å®æ—¶æ—¥å¿—

```bash
# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
tail -f runs/train/obstacle_v8n_16gpu_*/results.csv
```

### GPU ä½¿ç”¨ç‡

```bash
# ç›‘æ§æ‰€æœ‰ GPU
watch -n 1 nvidia-smi

# æˆ–ä½¿ç”¨ gpustatï¼ˆæ›´ç®€æ´ï¼‰
pip install gpustat
gpustat -i 1
```

## ğŸ• è®­ç»ƒæ—¶é—´ä¼°ç®—

```bash
python src/training/train_distributed.py estimate \
    --dataset-size 1000 \
    --epochs 100 \
    --gpus 16
```

ç¤ºä¾‹è¾“å‡ºï¼š
```
==================================================
è®­ç»ƒæ—¶é—´ä¼°ç®—
==================================================
æ•°æ®é›†å¤§å°: 1000 å¼ 
è®­ç»ƒè½®æ•°: 100
GPUæ•°é‡: 16
Batchå¤§å°: 256
--------------------------------------------------
GPUæ•ˆç‡: 85%
æœ‰æ•ˆåŠ é€Ÿ: 13.6x
æ¯è½®æ—¶é—´: 0.4 åˆ†é’Ÿ
æ€»æ—¶é—´: 0.6 å°æ—¶
==================================================
```

## ğŸ”§ æ•…éšœæ’é™¤

### NCCL é”™è¯¯

```bash
# è®¾ç½® NCCL ç¯å¢ƒå˜é‡
export NCCL_DEBUG=INFO
export NCCL_IB_DISABLE=1  # å¦‚æœæ²¡æœ‰ InfiniBand
export NCCL_SOCKET_IFNAME=eth0  # æŒ‡å®šç½‘ç»œæ¥å£
```

### OOM (æ˜¾å­˜ä¸è¶³)

```bash
# å‡å°‘ batch size
python src/training/train_distributed.py ddp \
    --batch 128 \  # å‡åŠ
    --imgsz 480    # æˆ–å‡å°å›¾åƒ
```

### å¤šå¡åŒæ­¥é—®é¢˜

```bash
# ä½¿ç”¨ GLOO åç«¯æ›¿ä»£ NCCL
export TORCH_DISTRIBUTED_BACKEND=gloo
```

## ğŸ“¦ è®­ç»ƒå®Œæˆå

### 1. ä¸‹è½½æ¨¡å‹

```bash
# åœ¨æœ¬åœ°æ‰§è¡Œ
rsync -avz user@gpu-server:/path/to/project/llm/runs/train/*/weights/best.pt \
    ./models/
```

### 2. ç»§ç»­ Day 3 ä¼˜åŒ–

```bash
# ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹
python src/optimization/model_optimization.py onnx models/best.pt
python src/optimization/model_optimization.py tensorrt models/best.pt
```

---

## ğŸ“‹ å‘½ä»¤é€ŸæŸ¥è¡¨

| ä»»åŠ¡ | å‘½ä»¤ |
|------|------|
| æ£€æŸ¥ç¯å¢ƒ | `bash scripts/train_multi_gpu.sh check` |
| å¼€å§‹è®­ç»ƒ | `bash scripts/train_multi_gpu.sh train 100 all` |
| æŒ‡å®šGPU | `bash scripts/train_multi_gpu.sh train 100 0,1,2,3,4,5,6,7` |
| æ€§èƒ½æµ‹è¯• | `bash scripts/train_multi_gpu.sh benchmark` |
| æ—¶é—´ä¼°ç®— | `bash scripts/train_multi_gpu.sh estimate 1000 100` |
| SLURMè„šæœ¬ | `bash scripts/train_multi_gpu.sh slurm` |

